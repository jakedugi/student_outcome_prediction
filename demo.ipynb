{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6062f660",
   "metadata": {},
   "source": [
    "# Student Outcome Prediction Demo\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/jakedugi/student_outcome_prediction/blob/main/demo.ipynb)\n",
    "\n",
    "This notebook demonstrates the core functionality of our student outcome prediction model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0b5d64",
   "metadata": {},
   "source": [
    "## ‚ö†Ô∏è Dataset Setup\n",
    "\n",
    "This demo uses data from [Kaggle](https://www.kaggle.com/datasets/thedevastator/higher-education-predictors-of-student-retention). To run it, you'll need to:\n",
    "\n",
    "1. Go to [Kaggle.com](https://www.kaggle.com) ‚Üí Account ‚Üí Create API Token\n",
    "2. Download your `kaggle.json` file\n",
    "3. Upload it when prompted below\n",
    "\n",
    "> üí° This is a one-time setup. Your API key will be stored securely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855c1d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the repository if running in Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    !git clone https://github.com/jakedugi/student_outcome_prediction.git\n",
    "    %cd student_outcome_prediction\n",
    "except ImportError:\n",
    "    pass  # Not running in Colab\n",
    "\n",
    "# Install required packages\n",
    "!pip install -q kaggle\n",
    "\n",
    "# Ensure data directory exists\n",
    "import os\n",
    "os.makedirs(\"data\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3dc3e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Kaggle credentials\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def setup_kaggle_credentials():\n",
    "    try:\n",
    "        from google.colab import files\n",
    "        print(\"üì§ Please upload your kaggle.json file...\")\n",
    "        uploaded = files.upload()\n",
    "        \n",
    "        if not uploaded:\n",
    "            raise Exception(\"No file was uploaded\")\n",
    "            \n",
    "        # Create Kaggle directory and move credentials\n",
    "        !mkdir -p ~/.kaggle\n",
    "        !cp kaggle.json ~/.kaggle/\n",
    "        !chmod 600 ~/.kaggle/kaggle.json\n",
    "        print(\"‚úÖ Kaggle credentials configured successfully!\")\n",
    "        \n",
    "    except ImportError:\n",
    "        # Local environment - check if credentials exist\n",
    "        kaggle_path = Path.home() / '.kaggle' / 'kaggle.json'\n",
    "        if not kaggle_path.exists():\n",
    "            print(\"‚ö†Ô∏è Please place your kaggle.json in:\", kaggle_path)\n",
    "            return False\n",
    "        print(\"‚úÖ Found existing Kaggle credentials\")\n",
    "    return True\n",
    "\n",
    "if setup_kaggle_credentials():\n",
    "    print(\"\\nüîÑ Downloading dataset...\")\n",
    "    try:\n",
    "        !kaggle datasets download -d thedevastator/higher-education-predictors-of-student-retention --quiet\n",
    "        !unzip -q higher-education-predictors-of-student-retention.zip -d data/\n",
    "        !rm higher-education-predictors-of-student-retention.zip\n",
    "        print(\"‚úÖ Dataset downloaded and extracted to data/\")\n",
    "    except Exception as e:\n",
    "        print(\"‚ùå Failed to download dataset:\", str(e))\n",
    "        print(\"‚ö†Ô∏è Please download manually from: https://www.kaggle.com/datasets/thedevastator/higher-education-predictors-of-student-retention\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e9b3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install remaining dependencies\n",
    "!pip install -q -r requirements.txt\n",
    "!pip install -q seaborn shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba1835c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install and import required packages\n",
    "!pip install -q seaborn shap\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "from src.pipeline import TrainingPipeline\n",
    "from src.config import TARGET\n",
    "\n",
    "# Apply Seaborn's modern styling\n",
    "sns.set_theme(style='whitegrid', font_scale=1.1)  # Slightly larger fonts for better readability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51c1a19",
   "metadata": {},
   "source": [
    "## Training the Model\n",
    "\n",
    "We'll train our model using data from the first 2 semesters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad181c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train pipeline\n",
    "pipeline = TrainingPipeline()\n",
    "results = pipeline.run(semesters=2)\n",
    "\n",
    "# Get best model results\n",
    "best_result = results[0]\n",
    "print(f\"Best model: {best_result['model']} with accuracy: {best_result['accuracy']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f00f8d",
   "metadata": {},
   "source": [
    "## Model Performance Analysis\n",
    "\n",
    "Let's analyze how well our model performs and understand what drives its predictions:\n",
    "\n",
    "### 1. Prediction Accuracy by Student Outcome\n",
    "\n",
    "First, let's look at how accurately our model predicts each type of student outcome:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2747a56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, class_names=None):\n",
    "    \"\"\"Plot confusion matrix with class labels.\"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # Default class names if none provided\n",
    "    if class_names is None:\n",
    "        class_names = ['Dropped Out', 'Continuing Studies', 'Graduated']\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=class_names,\n",
    "                yticklabels=class_names)\n",
    "    plt.title('Prediction Accuracy by Student Outcome', pad=20)\n",
    "    plt.ylabel('True Outcome')\n",
    "    plt.xlabel('Predicted Outcome')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot confusion matrix with meaningful labels\n",
    "plot_confusion_matrix(best_result['y_true'], best_result['y_pred'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abf4715",
   "metadata": {},
   "source": [
    "The confusion matrix above shows how well our model predicts each type of student outcome:\n",
    "\n",
    "- Each row represents the **true outcome** for a group of students\n",
    "- Each column shows what the model **predicted** for those students\n",
    "- Numbers in each cell show how many students fall into each category\n",
    "- Diagonal cells (top-left to bottom-right) show correct predictions\n",
    "- Off-diagonal cells show where the model made mistakes\n",
    "\n",
    "For example, if you look at the \"Dropped Out\" row, you can see:\n",
    "- How many actual dropout students were correctly identified\n",
    "- How many were incorrectly predicted to continue or graduate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec2d447",
   "metadata": {},
   "source": [
    "### 2. Understanding What Drives Predictions\n",
    "\n",
    "Now let's use SHAP (SHapley Additive exPlanations) values to understand:\n",
    "- Which factors most strongly influence student outcomes\n",
    "- How different features affect each type of outcome\n",
    "- What patterns lead to different predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b977fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate SHAP values\n",
    "print(\"üìä Calculating feature importance using SHAP...\")\n",
    "\n",
    "def plot_shap_analysis(model, X, feature_names):\n",
    "    \"\"\"Create SHAP summary and decision plots for model interpretation.\"\"\"\n",
    "    # Clean up feature names for display\n",
    "    display_names = [name.replace('_', ' ').title() for name in feature_names]\n",
    "    \n",
    "    try:\n",
    "        # Create explainer\n",
    "        if hasattr(model.estimator, 'predict_proba'):\n",
    "            explainer = shap.TreeExplainer(model.estimator) if hasattr(model.estimator, 'apply') else shap.Explainer(model.estimator)\n",
    "        else:\n",
    "            explainer = shap.TreeExplainer(model.estimator) if hasattr(model.estimator, 'apply') else shap.Explainer(model.estimator)\n",
    "        \n",
    "        # Calculate SHAP values\n",
    "        shap_values = explainer.shap_values(X)\n",
    "        if isinstance(shap_values, list):\n",
    "            shap_values = np.array(shap_values)\n",
    "\n",
    "        # Plot 1: Overall Summary Plot\n",
    "        plt.figure(figsize=(14, 10))  # Increased figure size\n",
    "        shap.summary_plot(\n",
    "            shap_values,\n",
    "            X,\n",
    "            feature_names=display_names,\n",
    "            show=False,\n",
    "            plot_size=(12, 8)\n",
    "        )\n",
    "        plt.title(\"Feature Impact Across All Outcomes\", pad=20)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # Plot class-specific summary plots\n",
    "        class_names = ['Dropout Risk', 'Continuing Studies', 'Graduation']\n",
    "        for i, class_name in enumerate(class_names):\n",
    "            plt.figure(figsize=(14, 10))\n",
    "            shap.summary_plot(\n",
    "                shap_values[i] if isinstance(shap_values, list) else shap_values[:,:,i],\n",
    "                X,\n",
    "                feature_names=display_names,\n",
    "                show=False,\n",
    "                plot_size=(12, 8)\n",
    "            )\n",
    "            plt.title(f\"Feature Impact for {class_name}\", pad=20)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "        # Decision plots for each class\n",
    "        expected_value = explainer.expected_value if hasattr(explainer, 'expected_value') else [0] * 3\n",
    "        if isinstance(expected_value, (int, float)):\n",
    "            expected_value = [expected_value]\n",
    "            \n",
    "        for i, class_name in enumerate(class_names):\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            shap.decision_plot(\n",
    "                expected_value[i] if isinstance(expected_value, list) else expected_value,\n",
    "                shap_values[i] if isinstance(shap_values, list) else shap_values[:,:,i],\n",
    "                X,\n",
    "                feature_names=display_names,\n",
    "                show=False\n",
    "            )\n",
    "            plt.title(f\"Decision Plot for {class_name}\", pad=20)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Could not compute SHAP values: {str(e)}\")\n",
    "        print(\"Falling back to feature importances...\")\n",
    "        \n",
    "        if hasattr(model.estimator, 'feature_importances_'):\n",
    "            importances = model.estimator.feature_importances_\n",
    "            indices = np.argsort(importances)[::-1][:15]\n",
    "            \n",
    "            fig, ax = plt.subplots(figsize=(12, 8))\n",
    "            sns.barplot(x=range(len(indices)), \n",
    "                       y=importances[indices],\n",
    "                       ax=ax,\n",
    "                       palette='viridis')\n",
    "            \n",
    "            plt.title('Most Important Factors in Predicting Student Outcomes', pad=20)\n",
    "            plt.xlabel('Factors')\n",
    "            plt.ylabel('Importance Score')\n",
    "            plt.xticks(range(len(indices)),\n",
    "                      [display_names[i] for i in indices],\n",
    "                      rotation=45,\n",
    "                      ha='right')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "# Generate SHAP analysis plots\n",
    "plot_shap_analysis(\n",
    "    best_result['model_obj'],\n",
    "    best_result['X_test'],\n",
    "    best_result['feature_names']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca279676",
   "metadata": {},
   "source": [
    "### How to Interpret These Plots\n",
    "\n",
    "1. **Overall Summary Plot**:\n",
    "   - Shows feature importance across all outcomes\n",
    "   - Features ordered by importance (top = most important)\n",
    "   - Color indicates feature value (red = high, blue = low)\n",
    "   - Width shows distribution of impact\n",
    "\n",
    "2. **Class-Specific Summary Plots**:\n",
    "   - One plot for each outcome (Dropout Risk, Continuing Studies, Graduation)\n",
    "   - Shows how features specifically influence each outcome\n",
    "   - Helps identify risk factors for dropping out vs. success factors for graduation\n",
    "\n",
    "3. **Decision Plots**:\n",
    "   - Shows how features combine to make predictions\n",
    "   - Each line represents a student's prediction path\n",
    "   - Start at base value (left), end at final prediction (right)\n",
    "   - Steeper slopes = stronger feature impact\n",
    "   - Direction shows whether feature increases/decreases likelihood\n",
    "\n",
    "This analysis helps identify:\n",
    "- Early warning signs of dropout risk\n",
    "- Key factors promoting student success\n",
    "- How different features interact to influence outcomes\n",
    "- Where to focus intervention efforts"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
