{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a2d5dbe",
   "metadata": {},
   "source": [
    "# Student Outcome Prediction Demo\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/jakedugi/student_outcome_prediction/blob/main/demo.ipynb)\n",
    "\n",
    "This notebook demonstrates the core functionality of our student outcome prediction model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24067ca2",
   "metadata": {},
   "source": [
    "## ‚ö†Ô∏è Dataset Setup\n",
    "\n",
    "This demo uses data from [Kaggle](https://www.kaggle.com/datasets/thedevastator/higher-education-predictors-of-student-retention). To run it, you'll need to:\n",
    "\n",
    "1. Go to [Kaggle.com](https://www.kaggle.com) ‚Üí Account ‚Üí Create API Token\n",
    "2. Download your `kaggle.json` file\n",
    "3. Upload it when prompted below\n",
    "\n",
    "> üí° This is a one-time setup. Your API key will be stored securely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da4349e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the repository if running in Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    !git clone https://github.com/jakedugi/student_outcome_prediction.git\n",
    "    %cd student_outcome_prediction\n",
    "except ImportError:\n",
    "    pass  # Not running in Colab\n",
    "\n",
    "# Install required packages\n",
    "!pip install -q kaggle\n",
    "\n",
    "# Ensure data directory exists\n",
    "import os\n",
    "os.makedirs(\"data\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5b8d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Kaggle credentials\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def setup_kaggle_credentials():\n",
    "    try:\n",
    "        from google.colab import files\n",
    "        print(\"üì§ Please upload your kaggle.json file...\")\n",
    "        uploaded = files.upload()\n",
    "        \n",
    "        if not uploaded:\n",
    "            raise Exception(\"No file was uploaded\")\n",
    "            \n",
    "        # Create Kaggle directory and move credentials\n",
    "        !mkdir -p ~/.kaggle\n",
    "        !cp kaggle.json ~/.kaggle/\n",
    "        !chmod 600 ~/.kaggle/kaggle.json\n",
    "        print(\"‚úÖ Kaggle credentials configured successfully!\")\n",
    "        \n",
    "    except ImportError:\n",
    "        # Local environment - check if credentials exist\n",
    "        kaggle_path = Path.home() / '.kaggle' / 'kaggle.json'\n",
    "        if not kaggle_path.exists():\n",
    "            print(\"‚ö†Ô∏è Please place your kaggle.json in:\", kaggle_path)\n",
    "            return False\n",
    "        print(\"‚úÖ Found existing Kaggle credentials\")\n",
    "    return True\n",
    "\n",
    "if setup_kaggle_credentials():\n",
    "    print(\"\\nüîÑ Downloading dataset...\")\n",
    "    try:\n",
    "        !kaggle datasets download -d thedevastator/higher-education-predictors-of-student-retention --quiet\n",
    "        !unzip -q higher-education-predictors-of-student-retention.zip -d data/\n",
    "        !rm higher-education-predictors-of-student-retention.zip\n",
    "        print(\"‚úÖ Dataset downloaded and extracted to data/\")\n",
    "    except Exception as e:\n",
    "        print(\"‚ùå Failed to download dataset:\", str(e))\n",
    "        print(\"‚ö†Ô∏è Please download manually from: https://www.kaggle.com/datasets/thedevastator/higher-education-predictors-of-student-retention\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a490d3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install remaining dependencies\n",
    "!pip install -q -r requirements.txt\n",
    "!pip install -q seaborn shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661bac8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install and import required packages\n",
    "!pip install -q seaborn shap\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "from src.pipeline import TrainingPipeline\n",
    "from src.config import TARGET\n",
    "\n",
    "# Apply Seaborn's modern styling\n",
    "sns.set_theme(style='whitegrid', font_scale=1.1)  # Slightly larger fonts for better readability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658fb592",
   "metadata": {},
   "source": [
    "## Training the Model\n",
    "\n",
    "We'll train our model using data from the first 2 semesters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d59489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train pipeline\n",
    "pipeline = TrainingPipeline()\n",
    "results = pipeline.run(semesters=2)\n",
    "\n",
    "# Get best model results\n",
    "best_result = results[0]\n",
    "print(f\"Best model: {best_result['model']} with accuracy: {best_result['accuracy']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0572b2",
   "metadata": {},
   "source": [
    "## Model Performance Analysis\n",
    "\n",
    "Let's analyze how well our model performs and understand what drives its predictions:\n",
    "\n",
    "### 1. Prediction Accuracy by Student Outcome\n",
    "\n",
    "First, let's look at how accurately our model predicts each type of student outcome:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f4dd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, class_names=None):\n",
    "    \"\"\"Plot confusion matrix with class labels.\"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # Default class names if none provided\n",
    "    if class_names is None:\n",
    "        class_names = ['Dropped Out', 'Continuing Studies', 'Graduated']\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=class_names,\n",
    "                yticklabels=class_names)\n",
    "    plt.title('Prediction Accuracy by Student Outcome', pad=20)\n",
    "    plt.ylabel('True Outcome')\n",
    "    plt.xlabel('Predicted Outcome')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot confusion matrix with meaningful labels\n",
    "plot_confusion_matrix(best_result['y_true'], best_result['y_pred'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee43d8e",
   "metadata": {},
   "source": [
    "The confusion matrix above shows how well our model predicts each type of student outcome:\n",
    "\n",
    "- Each row represents the **true outcome** for a group of students\n",
    "- Each column shows what the model **predicted** for those students\n",
    "- Numbers in each cell show how many students fall into each category\n",
    "- Diagonal cells (top-left to bottom-right) show correct predictions\n",
    "- Off-diagonal cells show where the model made mistakes\n",
    "\n",
    "For example, if you look at the \"Dropped Out\" row, you can see:\n",
    "- How many actual dropout students were correctly identified\n",
    "- How many were incorrectly predicted to continue or graduate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2e6be3",
   "metadata": {},
   "source": [
    "### 2. Understanding What Drives Predictions\n",
    "\n",
    "Now let's use SHAP (SHapley Additive exPlanations) values to understand:\n",
    "- Which factors most strongly influence student outcomes\n",
    "- How different features affect each type of outcome\n",
    "- What patterns lead to different predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb3b775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate SHAP values\n",
    "print(\"üìä Calculating feature importance using SHAP...\")\n",
    "\n",
    "def plot_shap_analysis(model, X, feature_names):\n",
    "    \"\"\"Create SHAP summary and decision plots for model interpretation.\"\"\"\n",
    "    # Clean up feature names for display\n",
    "    display_names = [name.replace('_', ' ').title() for name in feature_names]\n",
    "    \n",
    "    try:\n",
    "        # Create explainer\n",
    "        if hasattr(model.estimator, 'predict_proba'):\n",
    "            explainer = shap.TreeExplainer(model.estimator) if hasattr(model.estimator, 'apply') else shap.Explainer(model.estimator)\n",
    "        else:\n",
    "            explainer = shap.TreeExplainer(model.estimator) if hasattr(model.estimator, 'apply') else shap.Explainer(model.estimator)\n",
    "        \n",
    "        # Calculate SHAP values\n",
    "        shap_values = explainer.shap_values(X)\n",
    "        if isinstance(shap_values, list):\n",
    "            shap_values = np.array(shap_values)\n",
    "\n",
    "        # Plot class-specific summary plots\n",
    "        class_names = ['Dropout Risk', 'Continuing Studies', 'Graduation']\n",
    "        for i, class_name in enumerate(class_names):\n",
    "            plt.figure(figsize=(14, 10))\n",
    "            shap.summary_plot(\n",
    "                shap_values[i] if isinstance(shap_values, list) else shap_values[:,:,i],\n",
    "                X,\n",
    "                feature_names=display_names,\n",
    "                show=False,\n",
    "                plot_size=(12, 8)\n",
    "            )\n",
    "            plt.title(f\"Feature Impact for {class_name}\", pad=20)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "        # Combined decision plot for all classes\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        expected_value = explainer.expected_value if hasattr(explainer, 'expected_value') else [0] * 3\n",
    "        if isinstance(expected_value, (int, float)):\n",
    "            expected_value = [expected_value] * 3\n",
    "            \n",
    "        # Select a subset of samples for clearer visualization\n",
    "        n_samples = min(20, len(X))\n",
    "        sample_indices = np.random.choice(len(X), n_samples, replace=False)\n",
    "        X_subset = X.iloc[sample_indices] if hasattr(X, 'iloc') else X[sample_indices]\n",
    "        \n",
    "        # Get predictions for coloring\n",
    "        if hasattr(model.estimator, 'predict_proba'):\n",
    "            predictions = model.estimator.predict_proba(X_subset)\n",
    "            pred_classes = np.argmax(predictions, axis=1)\n",
    "        else:\n",
    "            pred_classes = model.estimator.predict(X_subset)\n",
    "        \n",
    "        # Create color map for different classes\n",
    "        colors = ['#FF9999', '#66B2FF', '#99FF99']\n",
    "        sample_colors = [colors[pred] for pred in pred_classes]\n",
    "        \n",
    "        try:\n",
    "            shap.decision_plot(\n",
    "                expected_value,\n",
    "                [shap_values[i][sample_indices] if isinstance(shap_values, list) \n",
    "                 else shap_values[sample_indices,:,i] for i in range(3)],\n",
    "                X_subset,\n",
    "                feature_names=display_names,\n",
    "                link='logit',\n",
    "                feature_order='importance',\n",
    "                plot_color=sample_colors,\n",
    "                show=False\n",
    "            )\n",
    "            plt.title(\"Decision Paths Across All Outcomes\", pad=20)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Could not compute combined decision plot: {str(e)}\")\n",
    "            \n",
    "        # Feature importance plot\n",
    "        if hasattr(model.estimator, 'feature_importances_'):\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            importances = model.estimator.feature_importances_\n",
    "            indices = np.argsort(importances)[::-1][:15]\n",
    "            \n",
    "            plt.figure(figsize=(12, 8))\n",
    "            bars = plt.barh(range(len(indices)), importances[indices], color='cornflowerblue')\n",
    "            \n",
    "            plt.title('Most Important Factors in Predicting Student Outcomes', pad=20)\n",
    "            plt.xlabel('Importance Score')\n",
    "            plt.ylabel('Factors')\n",
    "            plt.yticks(range(len(indices)), [display_names[i] for i in indices])\n",
    "            \n",
    "            # Add value labels on the bars\n",
    "            for bar in bars:\n",
    "                width = bar.get_width()\n",
    "                plt.text(width, bar.get_y() + bar.get_height()/2, \n",
    "                        f'{width:.3f}', \n",
    "                        ha='left', va='center', fontsize=10)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Could not compute SHAP values: {str(e)}\")\n",
    "\n",
    "# Generate SHAP analysis plots\n",
    "plot_shap_analysis(\n",
    "    best_result['model_obj'],\n",
    "    best_result['X_test'],\n",
    "    best_result['feature_names']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0426f2c4",
   "metadata": {},
   "source": [
    "### How to Interpret These Plots\n",
    "\n",
    "1. **Class-Specific Summary Plots**:\n",
    "   - One plot for each outcome (Dropout Risk, Continuing Studies, Graduation)\n",
    "   - Shows how features specifically influence each outcome\n",
    "   - Features ordered by importance (top = most important)\n",
    "   - Color indicates feature value (red = high, blue = low)\n",
    "   - Width shows distribution of impact\n",
    "\n",
    "2. **Combined Decision Plot**:\n",
    "   - Shows prediction paths for multiple students across all outcomes\n",
    "   - Each line represents a student's path to their predicted outcome\n",
    "   - Colors indicate the predicted class:\n",
    "     - Red = Dropout Risk\n",
    "     - Blue = Continuing Studies\n",
    "     - Green = Graduation\n",
    "   - Steeper slopes indicate stronger feature impact\n",
    "   - Path direction shows whether features increase/decrease likelihood\n",
    "\n",
    "3. **Feature Importance Plot**:\n",
    "   - Shows overall ranking of feature importance\n",
    "   - Longer bars indicate stronger predictive power\n",
    "   - Values show quantitative importance scores\n",
    "   - Helps identify key factors for intervention\n",
    "\n",
    "This analysis helps identify:\n",
    "- Early warning signs of dropout risk\n",
    "- Key factors promoting student success\n",
    "- How different features interact to influence outcomes\n",
    "- Where to focus intervention efforts"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
