{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52cfe961",
   "metadata": {},
   "source": [
    "# Student Outcome Prediction Demo\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/jakedugi/student_outcome_prediction/blob/main/demo.ipynb)\n",
    "\n",
    "This notebook demonstrates the core functionality of our student outcome prediction model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00470336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the repository if running in Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    !git clone https://github.com/jakedugi/student_outcome_prediction.git\n",
    "    %cd student_outcome_prediction\n",
    "except ImportError:\n",
    "    pass  # Not running in Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd44352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q -r requirements.txt\n",
    "!pip install -q seaborn shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1d4e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "from src.pipeline import TrainingPipeline\n",
    "from src.config import TARGET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740f81c1",
   "metadata": {},
   "source": [
    "## Training the Model\n",
    "\n",
    "We'll train our model using data from the first 2 semesters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee5f6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train pipeline\n",
    "pipeline = TrainingPipeline()\n",
    "results = pipeline.run(semesters=2)\n",
    "\n",
    "# Get best model results\n",
    "best_result = results[0]\n",
    "print(f\"Best model: {best_result['model']} with accuracy: {best_result['accuracy']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b681cef1",
   "metadata": {},
   "source": [
    "## Model Performance Visualization\n",
    "\n",
    "Let's visualize the confusion matrix to understand our model's performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f92ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, title='Confusion Matrix'):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(title)\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.show()\n",
    "\n",
    "# Plot confusion matrix\n",
    "plot_confusion_matrix(best_result['y_true'], best_result['y_pred'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74440dae",
   "metadata": {},
   "source": [
    "## Feature Importance Analysis\n",
    "\n",
    "Let's examine which features are most important for prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327fd34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importance(model, X, feature_names):\n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        # For tree-based models\n",
    "        importances = model.feature_importances_\n",
    "        indices = np.argsort(importances)[::-1]\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.title('Feature Importances')\n",
    "        plt.bar(range(X.shape[1]), importances[indices])\n",
    "        plt.xticks(range(X.shape[1]), [feature_names[i] for i in indices], rotation=45, ha='right')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        # For other models, use SHAP values\n",
    "        explainer = shap.Explainer(model, X)\n",
    "        shap_values = explainer(X)\n",
    "        shap.summary_plot(shap_values, X, feature_names=feature_names, show=False)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Plot feature importance\n",
    "plot_feature_importance(best_result['model_obj'], best_result['X_test'], best_result['feature_names'])"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
