{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4ae2dac",
   "metadata": {},
   "source": [
    "# Student Outcome Prediction Demo\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/jakedugi/student_outcome_prediction/blob/main/demo.ipynb)\n",
    "\n",
    "This notebook demonstrates the core functionality of our student outcome prediction model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a3c6bb",
   "metadata": {},
   "source": [
    "## ‚ö†Ô∏è Dataset Setup\n",
    "\n",
    "This demo uses data from [Kaggle](https://www.kaggle.com/datasets/thedevastator/higher-education-predictors-of-student-retention). To run it, you'll need to:\n",
    "\n",
    "1. Go to [Kaggle.com](https://www.kaggle.com) ‚Üí Account ‚Üí Create API Token\n",
    "2. Download your `kaggle.json` file\n",
    "3. Upload it when prompted below\n",
    "\n",
    "> üí° This is a one-time setup. Your API key will be stored securely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da32ff81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the repository if running in Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    !git clone https://github.com/jakedugi/student_outcome_prediction.git\n",
    "    %cd student_outcome_prediction\n",
    "except ImportError:\n",
    "    pass  # Not running in Colab\n",
    "\n",
    "# Install required packages\n",
    "!pip install -q kaggle\n",
    "\n",
    "# Ensure data directory exists\n",
    "import os\n",
    "os.makedirs(\"data\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f7633f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Kaggle credentials\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def setup_kaggle_credentials():\n",
    "    try:\n",
    "        from google.colab import files\n",
    "        print(\"üì§ Please upload your kaggle.json file...\")\n",
    "        uploaded = files.upload()\n",
    "        \n",
    "        if not uploaded:\n",
    "            raise Exception(\"No file was uploaded\")\n",
    "            \n",
    "        # Create Kaggle directory and move credentials\n",
    "        !mkdir -p ~/.kaggle\n",
    "        !cp kaggle.json ~/.kaggle/\n",
    "        !chmod 600 ~/.kaggle/kaggle.json\n",
    "        print(\"‚úÖ Kaggle credentials configured successfully!\")\n",
    "        \n",
    "    except ImportError:\n",
    "        # Local environment - check if credentials exist\n",
    "        kaggle_path = Path.home() / '.kaggle' / 'kaggle.json'\n",
    "        if not kaggle_path.exists():\n",
    "            print(\"‚ö†Ô∏è Please place your kaggle.json in:\", kaggle_path)\n",
    "            return False\n",
    "        print(\"‚úÖ Found existing Kaggle credentials\")\n",
    "    return True\n",
    "\n",
    "if setup_kaggle_credentials():\n",
    "    print(\"\\nüîÑ Downloading dataset...\")\n",
    "    try:\n",
    "        !kaggle datasets download -d thedevastator/higher-education-predictors-of-student-retention --quiet\n",
    "        !unzip -q higher-education-predictors-of-student-retention.zip -d data/\n",
    "        !rm higher-education-predictors-of-student-retention.zip\n",
    "        print(\"‚úÖ Dataset downloaded and extracted to data/\")\n",
    "    except Exception as e:\n",
    "        print(\"‚ùå Failed to download dataset:\", str(e))\n",
    "        print(\"‚ö†Ô∏è Please download manually from: https://www.kaggle.com/datasets/thedevastator/higher-education-predictors-of-student-retention\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f016c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install remaining dependencies\n",
    "!pip install -q -r requirements.txt\n",
    "!pip install -q seaborn shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9345e4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "from src.pipeline import TrainingPipeline\n",
    "from src.config import TARGET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac48acd",
   "metadata": {},
   "source": [
    "## Training the Model\n",
    "\n",
    "We'll train our model using data from the first 2 semesters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95048993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train pipeline\n",
    "pipeline = TrainingPipeline()\n",
    "results = pipeline.run(semesters=2)\n",
    "\n",
    "# Get best model results\n",
    "best_result = results[0]\n",
    "print(f\"Best model: {best_result['model']} with accuracy: {best_result['accuracy']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b7e8d3",
   "metadata": {},
   "source": [
    "## Model Performance Visualization\n",
    "\n",
    "Let's visualize the confusion matrix to understand our model's performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b464a312",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, title='Confusion Matrix'):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(title)\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.show()\n",
    "\n",
    "# Plot confusion matrix\n",
    "plot_confusion_matrix(best_result['y_true'], best_result['y_pred'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892dffc8",
   "metadata": {},
   "source": [
    "## Feature Importance Analysis\n",
    "\n",
    "Let's examine which factors most strongly influence student outcomes. This analysis helps us understand:\n",
    "- What predicts student success\n",
    "- Where to focus intervention efforts\n",
    "- Early warning signs of dropout risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50b1010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define class descriptions for better readability\n",
    "class_descriptions = {\n",
    "    0: \"Dropout Risk\",\n",
    "    1: \"Continuing Studies\", \n",
    "    2: \"Likely to Graduate\"\n",
    "}\n",
    "\n",
    "def plot_feature_importance(model_wrapper, X, feature_names, max_display=15):\n",
    "    \"\"\"Plot feature importance with improved visualization and explanations.\"\"\"\n",
    "    # Clean up feature names for display\n",
    "    display_names = [name.replace('_', ' ').title() for name in feature_names]\n",
    "    \n",
    "    # Use seaborn style for better aesthetics\n",
    "    plt.style.use('seaborn')\n",
    "    \n",
    "    if hasattr(model_wrapper.estimator, 'feature_importances_'):\n",
    "        # For tree-based models (Random Forest, XGBoost, etc.)\n",
    "        importances = model_wrapper.estimator.feature_importances_\n",
    "        indices = np.argsort(importances)[::-1][:max_display]\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "        bars = ax.bar(range(len(indices)), importances[indices])\n",
    "        \n",
    "        # Add value labels on top of bars\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                   f'{height:.3f}',\n",
    "                   ha='center', va='bottom')\n",
    "        \n",
    "        plt.title(f'Feature Impact on Student Outcomes\\n{model_wrapper.model_name}', \n",
    "                 pad=20, wrap=True)\n",
    "        plt.xlabel('Features')\n",
    "        plt.ylabel('Importance Score')\n",
    "        plt.xticks(range(len(indices)), \n",
    "                  [display_names[i] for i in indices],\n",
    "                  rotation=45, ha='right')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        try:\n",
    "            # For models without feature_importances_, use SHAP\n",
    "            predict_fn = lambda x: model_wrapper.estimator.predict_proba(x)[:, 1] if hasattr(model_wrapper.estimator, 'predict_proba') else model_wrapper.estimator.predict\n",
    "            \n",
    "            explainer = shap.Explainer(predict_fn, X)\n",
    "            shap_values = explainer(X)\n",
    "            \n",
    "            # Handle different SHAP value shapes\n",
    "            if isinstance(shap_values, shap.Explanation):\n",
    "                if len(shap_values.shape) > 2:  # Multiclass case\n",
    "                    # Plot for all classes\n",
    "                    for class_idx in range(shap_values.shape[2]):\n",
    "                        plt.figure(figsize=(12, 8))\n",
    "                        class_name = class_descriptions.get(class_idx, f\"Class {class_idx}\")\n",
    "                        \n",
    "                        # Custom summary plot with better formatting\n",
    "                        shap.summary_plot(\n",
    "                            shap_values[:, :, class_idx],\n",
    "                            X,\n",
    "                            feature_names=display_names,\n",
    "                            plot_type=\"bar\",\n",
    "                            max_display=max_display,\n",
    "                            show=False,\n",
    "                            plot_size=(12, 8)\n",
    "                        )\n",
    "                        \n",
    "                        plt.title(f'Feature Impact on {class_name} Outcome\\n{model_wrapper.model_name}',\n",
    "                                pad=20, wrap=True)\n",
    "                        plt.xlabel('Average Impact on Prediction (SHAP Value)')\n",
    "                        \n",
    "                        # Add legend explaining SHAP values\n",
    "                        plt.figtext(1.02, 0.5, \n",
    "                                  'How to read this plot:\\n\\n' +\n",
    "                                  '‚Ä¢ Longer bars = Stronger impact\\n' +\n",
    "                                  '‚Ä¢ Red = Higher feature values\\n' +\n",
    "                                  '‚Ä¢ Blue = Lower feature values\\n' +\n",
    "                                  '‚Ä¢ Values show average impact\\n' +\n",
    "                                  '  on model predictions',\n",
    "                                  fontsize=10, ha='left', va='center',\n",
    "                                  bbox=dict(facecolor='white', alpha=0.8))\n",
    "                        \n",
    "                        plt.tight_layout()\n",
    "                        plt.show()\n",
    "                else:  # Binary classification or regression\n",
    "                    plt.figure(figsize=(12, 8))\n",
    "                    shap.summary_plot(\n",
    "                        shap_values,\n",
    "                        X,\n",
    "                        feature_names=display_names,\n",
    "                        plot_type=\"bar\",\n",
    "                        max_display=max_display,\n",
    "                        show=False\n",
    "                    )\n",
    "                    plt.title(f'Feature Impact on Student Outcomes\\n{model_wrapper.model_name}',\n",
    "                            pad=20, wrap=True)\n",
    "                    plt.xlabel('Average Impact on Prediction (SHAP Value)')\n",
    "                    plt.tight_layout()\n",
    "                    plt.show()\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Could not compute SHAP values: {str(e)}\")\n",
    "            print(\"Falling back to coefficients if available...\")\n",
    "            \n",
    "            if hasattr(model_wrapper.estimator, 'coef_'):\n",
    "                coef = model_wrapper.estimator.coef_\n",
    "                coef = coef if len(coef.shape) == 1 else coef[0]\n",
    "                importance = np.abs(coef)\n",
    "                indices = np.argsort(importance)[::-1][:max_display]\n",
    "                \n",
    "                plt.figure(figsize=(12, 8))\n",
    "                plt.title(f'Feature Impact on Student Outcomes\\n{model_wrapper.model_name}',\n",
    "                         pad=20, wrap=True)\n",
    "                plt.bar(range(len(indices)), importance[indices])\n",
    "                plt.xlabel('Features')\n",
    "                plt.ylabel('Absolute Coefficient Value')\n",
    "                plt.xticks(range(len(indices)), \n",
    "                          [display_names[i] for i in indices],\n",
    "                          rotation=45, ha='right')\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "\n",
    "print(\"üìä Analyzing what influences student outcomes...\")\n",
    "plot_feature_importance(\n",
    "    best_result['model_obj'],\n",
    "    best_result['X_test'],\n",
    "    best_result['feature_names']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e83cb5",
   "metadata": {},
   "source": [
    "### Key Insights from Feature Importance\n",
    "\n",
    "The plot above shows which factors most strongly influence student outcomes. Here's how to interpret it:\n",
    "\n",
    "1. **Bar Length**: Longer bars indicate stronger influence on predictions\n",
    "2. **Colors** (for SHAP plots):\n",
    "   - Red = Higher values of that feature\n",
    "   - Blue = Lower values of that feature\n",
    "3. **Direction**:\n",
    "   - Positive values (right) increase likelihood of the outcome\n",
    "   - Negative values (left) decrease likelihood\n",
    "\n",
    "This analysis helps identify early warning signs and potential intervention points to improve student success."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
