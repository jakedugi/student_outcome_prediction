{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6bcc6af2",
   "metadata": {},
   "source": [
    "# Student Outcome Prediction Demo\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/jakedugi/student_outcome_prediction/blob/main/demo.ipynb)\n",
    "\n",
    "This notebook demonstrates the core functionality of our student outcome prediction model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a6d4a5",
   "metadata": {},
   "source": [
    "## ‚ö†Ô∏è Dataset Setup\n",
    "\n",
    "This demo uses data from [Kaggle](https://www.kaggle.com/datasets/thedevastator/higher-education-predictors-of-student-retention). To run it, you'll need to:\n",
    "\n",
    "1. Go to [Kaggle.com](https://www.kaggle.com) ‚Üí Account ‚Üí Create API Token\n",
    "2. Download your `kaggle.json` file\n",
    "3. Upload it when prompted below\n",
    "\n",
    "> üí° This is a one-time setup. Your API key will be stored securely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7861410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the repository if running in Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    !git clone https://github.com/jakedugi/student_outcome_prediction.git\n",
    "    %cd student_outcome_prediction\n",
    "except ImportError:\n",
    "    pass  # Not running in Colab\n",
    "\n",
    "# Install required packages\n",
    "!pip install -q kaggle\n",
    "\n",
    "# Ensure data directory exists\n",
    "import os\n",
    "os.makedirs(\"data\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63ec6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Kaggle credentials\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def setup_kaggle_credentials():\n",
    "    try:\n",
    "        from google.colab import files\n",
    "        print(\"üì§ Please upload your kaggle.json file...\")\n",
    "        uploaded = files.upload()\n",
    "        \n",
    "        if not uploaded:\n",
    "            raise Exception(\"No file was uploaded\")\n",
    "            \n",
    "        # Create Kaggle directory and move credentials\n",
    "        !mkdir -p ~/.kaggle\n",
    "        !cp kaggle.json ~/.kaggle/\n",
    "        !chmod 600 ~/.kaggle/kaggle.json\n",
    "        print(\"‚úÖ Kaggle credentials configured successfully!\")\n",
    "        \n",
    "    except ImportError:\n",
    "        # Local environment - check if credentials exist\n",
    "        kaggle_path = Path.home() / '.kaggle' / 'kaggle.json'\n",
    "        if not kaggle_path.exists():\n",
    "            print(\"‚ö†Ô∏è Please place your kaggle.json in:\", kaggle_path)\n",
    "            return False\n",
    "        print(\"‚úÖ Found existing Kaggle credentials\")\n",
    "    return True\n",
    "\n",
    "if setup_kaggle_credentials():\n",
    "    print(\"\\nüîÑ Downloading dataset...\")\n",
    "    try:\n",
    "        !kaggle datasets download -d thedevastator/higher-education-predictors-of-student-retention --quiet\n",
    "        !unzip -q higher-education-predictors-of-student-retention.zip -d data/\n",
    "        !rm higher-education-predictors-of-student-retention.zip\n",
    "        print(\"‚úÖ Dataset downloaded and extracted to data/\")\n",
    "    except Exception as e:\n",
    "        print(\"‚ùå Failed to download dataset:\", str(e))\n",
    "        print(\"‚ö†Ô∏è Please download manually from: https://www.kaggle.com/datasets/thedevastator/higher-education-predictors-of-student-retention\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73d837f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install remaining dependencies\n",
    "!pip install -q -r requirements.txt\n",
    "!pip install -q seaborn shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d9c3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install and import required packages\n",
    "!pip install -q seaborn shap\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "from src.pipeline import TrainingPipeline\n",
    "from src.config import TARGET\n",
    "\n",
    "# Apply Seaborn's modern styling\n",
    "sns.set_theme(style='whitegrid', font_scale=1.1)  # Slightly larger fonts for better readability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3724d8",
   "metadata": {},
   "source": [
    "## Training the Model\n",
    "\n",
    "We'll train our model using data from the first 2 semesters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d34abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train pipeline\n",
    "pipeline = TrainingPipeline()\n",
    "results = pipeline.run(semesters=2)\n",
    "\n",
    "# Get best model results\n",
    "best_result = results[0]\n",
    "print(f\"Best model: {best_result['model']} with accuracy: {best_result['accuracy']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2cee311",
   "metadata": {},
   "source": [
    "## Model Performance Analysis\n",
    "\n",
    "Let's analyze how well our model performs and understand what drives its predictions:\n",
    "\n",
    "### 1. Prediction Accuracy by Student Outcome\n",
    "\n",
    "First, let's look at how accurately our model predicts each type of student outcome:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603e77e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, class_names=None):\n",
    "    \"\"\"Plot confusion matrix with class labels.\"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # Default class names if none provided\n",
    "    if class_names is None:\n",
    "        class_names = ['Dropped Out', 'Continuing Studies', 'Graduated']\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=class_names,\n",
    "                yticklabels=class_names)\n",
    "    plt.title('Prediction Accuracy by Student Outcome', pad=20)\n",
    "    plt.ylabel('True Outcome')\n",
    "    plt.xlabel('Predicted Outcome')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot confusion matrix with meaningful labels\n",
    "plot_confusion_matrix(best_result['y_true'], best_result['y_pred'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d244f22",
   "metadata": {},
   "source": [
    "The confusion matrix above shows how well our model predicts each type of student outcome:\n",
    "\n",
    "- Each row represents the **true outcome** for a group of students\n",
    "- Each column shows what the model **predicted** for those students\n",
    "- Numbers in each cell show how many students fall into each category\n",
    "- Diagonal cells (top-left to bottom-right) show correct predictions\n",
    "- Off-diagonal cells show where the model made mistakes\n",
    "\n",
    "For example, if you look at the \"Dropped Out\" row, you can see:\n",
    "- How many actual dropout students were correctly identified\n",
    "- How many were incorrectly predicted to continue or graduate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9dd1360",
   "metadata": {},
   "source": [
    "### 2. Understanding What Drives Predictions\n",
    "\n",
    "Now let's use SHAP (SHapley Additive exPlanations) values to understand:\n",
    "- Which factors most strongly influence student outcomes\n",
    "- How different features affect each type of outcome\n",
    "- What patterns lead to different predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d5505f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate SHAP values\n",
    "print(\"üìä Calculating feature importance using SHAP...\")\n",
    "\n",
    "def plot_shap_summary_and_importance(model, X, feature_names):\n",
    "    \"\"\"Create SHAP summary plots and feature importance plot.\"\"\"\n",
    "    # Clean up feature names for display\n",
    "    display_names = [name.replace('_', ' ').title() for name in feature_names]\n",
    "    \n",
    "    try:\n",
    "        # Create explainer\n",
    "        if hasattr(model.estimator, 'predict_proba'):\n",
    "            explainer = shap.TreeExplainer(model.estimator) if hasattr(model.estimator, 'apply') else shap.Explainer(model.estimator)\n",
    "        else:\n",
    "            explainer = shap.TreeExplainer(model.estimator) if hasattr(model.estimator, 'apply') else shap.Explainer(model.estimator)\n",
    "        \n",
    "        # Calculate SHAP values\n",
    "        shap_values = explainer.shap_values(X)\n",
    "        if isinstance(shap_values, list):\n",
    "            shap_values = np.array(shap_values)\n",
    "\n",
    "        # Plot class-specific summary plots\n",
    "        class_names = ['Dropout Risk', 'Continuing Studies', 'Graduation']\n",
    "        for i, class_name in enumerate(class_names):\n",
    "            plt.figure(figsize=(14, 10))\n",
    "            shap.summary_plot(\n",
    "                shap_values[i] if isinstance(shap_values, list) else shap_values[:,:,i],\n",
    "                X,\n",
    "                feature_names=display_names,\n",
    "                show=False,\n",
    "                plot_size=(12, 8)\n",
    "            )\n",
    "            plt.title(f\"Feature Impact for {class_name}\", pad=20)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "        # Feature importance plot (vertical bars)\n",
    "        if hasattr(model.estimator, 'feature_importances_'):\n",
    "            importances = model.estimator.feature_importances_\n",
    "            indices = np.argsort(importances)[::-1][:15]\n",
    "            \n",
    "            plt.figure(figsize=(12, 8))\n",
    "            bars = plt.bar(range(len(indices)), importances[indices], color='cornflowerblue')\n",
    "            \n",
    "            plt.title('Most Important Factors in Predicting Student Outcomes', pad=20)\n",
    "            plt.ylabel('Importance Score')\n",
    "            plt.xlabel('Factors')\n",
    "            \n",
    "            # Rotate x-axis labels for better readability\n",
    "            plt.xticks(range(len(indices)), \n",
    "                      [display_names[i] for i in indices],\n",
    "                      rotation=45,\n",
    "                      ha='right')\n",
    "            \n",
    "            # Add value labels on top of bars\n",
    "            for bar in bars:\n",
    "                height = bar.get_height()\n",
    "                plt.text(bar.get_x() + bar.get_width()/2, height,\n",
    "                        f'{height:.3f}',\n",
    "                        ha='center', va='bottom')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Could not compute SHAP values: {str(e)}\")\n",
    "\n",
    "def plot_multioutput_decision(model, X, feature_names):\n",
    "    \"\"\"Create multioutput decision plot with proper list handling.\"\"\"\n",
    "    display_names = [name.replace('_', ' ').title() for name in feature_names]\n",
    "    \n",
    "    try:\n",
    "        # Create explainer\n",
    "        if hasattr(model.estimator, 'predict_proba'):\n",
    "            explainer = shap.TreeExplainer(model.estimator) if hasattr(model.estimator, 'apply') else shap.Explainer(model.estimator)\n",
    "        else:\n",
    "            explainer = shap.TreeExplainer(model.estimator) if hasattr(model.estimator, 'apply') else shap.Explainer(model.estimator)\n",
    "        \n",
    "        # Get raw SHAP values and base values\n",
    "        raw_base = explainer.expected_value\n",
    "        raw_shap = explainer.shap_values(X)\n",
    "        \n",
    "        # Convert base values to list\n",
    "        base_values = raw_base if isinstance(raw_base, list) else list(raw_base)\n",
    "        \n",
    "        # Convert SHAP values to list format for multioutput\n",
    "        if isinstance(raw_shap, np.ndarray) and raw_shap.ndim == 3:\n",
    "            shap_values = [raw_shap[i] for i in range(raw_shap.shape[0])]\n",
    "        elif isinstance(raw_shap, list):\n",
    "            shap_values = raw_shap\n",
    "        else:\n",
    "            shap_values = list(raw_shap)\n",
    "        \n",
    "        # Select subset of samples for clearer visualization\n",
    "        n_samples = min(20, len(X))\n",
    "        sample_indices = np.random.choice(len(X), n_samples, replace=False)\n",
    "        X_subset = X.iloc[sample_indices] if hasattr(X, 'iloc') else X[sample_indices]\n",
    "        \n",
    "        # Prepare SHAP values for selected samples\n",
    "        subset_shap_values = [sv[sample_indices] for sv in shap_values]\n",
    "        \n",
    "        plt.figure(figsize=(15, 10))\n",
    "        shap.multioutput_decision_plot(\n",
    "            base_values,\n",
    "            subset_shap_values,\n",
    "            X_subset,\n",
    "            feature_names=display_names,\n",
    "            feature_order='importance',\n",
    "            highlight=list(range(n_samples)),\n",
    "            show=False\n",
    "        )\n",
    "        plt.title(\"Decision Paths Across All Outcomes\", pad=20)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Could not compute multioutput decision plot: {str(e)}\")\n",
    "\n",
    "# Generate SHAP analysis plots\n",
    "print(\"\\nüìä Generating summary and importance plots...\")\n",
    "plot_shap_summary_and_importance(\n",
    "    best_result['model_obj'],\n",
    "    best_result['X_test'],\n",
    "    best_result['feature_names']\n",
    ")\n",
    "\n",
    "print(\"\\nüìä Generating multioutput decision plot...\")\n",
    "plot_multioutput_decision(\n",
    "    best_result['model_obj'],\n",
    "    best_result['X_test'],\n",
    "    best_result['feature_names']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84be586",
   "metadata": {},
   "source": [
    "### How to Interpret These Plots\n",
    "\n",
    "1. **Class-Specific Summary Plots**:\n",
    "   - One plot for each outcome (Dropout Risk, Continuing Studies, Graduation)\n",
    "   - Shows how features specifically influence each outcome\n",
    "   - Features ordered by importance (top = most important)\n",
    "   - Color indicates feature value (red = high, blue = low)\n",
    "   - Width shows distribution of impact\n",
    "\n",
    "2. **Combined Decision Plot**:\n",
    "   - Shows prediction paths for multiple students across all outcomes\n",
    "   - Each line represents a student's path to their predicted outcome\n",
    "   - Features are ordered by importance (top to bottom)\n",
    "   - Line paths show how each feature contributes to the final prediction\n",
    "   - Steeper slopes indicate stronger feature impact\n",
    "   - Direction shows whether features increase/decrease likelihood\n",
    "\n",
    "3. **Feature Importance Plot**:\n",
    "   - Shows overall ranking of feature importance\n",
    "   - Taller bars indicate stronger predictive power\n",
    "   - Values show quantitative importance scores\n",
    "   - Helps identify key factors for intervention\n",
    "\n",
    "This analysis helps identify:\n",
    "- Early warning signs of dropout risk\n",
    "- Key factors promoting student success\n",
    "- How different features interact to influence outcomes\n",
    "- Where to focus intervention efforts"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
